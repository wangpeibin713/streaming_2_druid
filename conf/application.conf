spark: {
  master: "local[*]"
  totalExecutorCores: "10"
  executorMemory: "15G"
  memoryFraction:"0.6"
  concurrentJobs: "6"
  streamingWindow: 60
  blockQueueSize:"100"
}
dataSource: {
  kafka :{
    zookeeper:"127.0.0.1:2181"
    timeout:"50000"
    group:"demo"
  },
  topics :[
    {
      name : "world"
      enabled: true
      topic: "world_count"
      parallel: 1
      type: 0
    }]
}

task: [{
  name : "world_count"
  window_size: 60
  sql : "select day, hour,minute,vendor_id, model_type, sum(imp) as imp, sum(clk) as clk from all_log group by day, hour,minute,vendor_id, model_type"
  jdbc: {
    driver : "org.postgresql.Driver"
    url : "jdbc:postgresql://127.0.0.1:5432/world_count"
    table : "world_count"
    user : "work"
    password : "123456"
  }
}]

health:{
  type: 2
  uri: "graphite.zamplus.local:2113"
  prefix: "soraka.zampda3.streaming"
}
